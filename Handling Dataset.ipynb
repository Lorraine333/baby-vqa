{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Handling\n",
    "\n",
    "The VQA dataset contains ~120K images and ~330K question/answer pairs and is quite large for this baby VQA project. Therefore, we will extract a small set of it for training and testing our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a bit of setup as usual\n",
    "import h5py, json\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Loading the full VQA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5_img_file_train = h5py.File('data/vqa_data_img_vgg_train.h5', 'r')\n",
    "fv_im_train = h5_img_file_train.get('/images_train') # 82460 x 14 x 14 x 512\n",
    "\n",
    "h5_img_file_test = h5py.File('data/vqa_data_img_vgg_test.h5', 'r')\n",
    "fv_im_test = h5_img_file_test.get('/images_test') # 40504 x 14 x 14 x 512\n",
    "\n",
    "h5_ques_file = h5py.File('data/vqa_data_prepro.h5', 'r')\n",
    "ques_train = h5_ques_file.get('/ques_train') # 215375 x 26\n",
    "ques_len_train = h5_ques_file.get('/ques_len_train') # 215375 x 1\n",
    "img_pos_train = h5_ques_file.get('/img_pos_train') # 215375 x 1\n",
    "ques_id_train = h5_ques_file.get('/ques_id_train') # 215375 x 1\n",
    "answers = h5_ques_file.get('/answers') # 215375 x 1\n",
    "split_train = h5_ques_file.get('/split_train') # 215375 x 1\n",
    "\n",
    "ques_test = h5_ques_file.get('/ques_test') # 121512 x26\n",
    "ques_len_test = h5_ques_file.get('/ques_len_test')\n",
    "img_pos_test = h5_ques_file.get('/img_pos_test')\n",
    "ques_id_test = h5_ques_file.get('/ques_id_test')\n",
    "split_test = h5_ques_file.get('/split_test')\n",
    "ans_test = h5_ques_file.get('/ans_test')\n",
    "\n",
    "json_file = json.load(open('data/vqa_data_prepro.json', 'r'))\n",
    "ix_to_word = json_file['ix_to_word']\n",
    "ix_to_ans = json_file['ix_to_ans']\n",
    "\n",
    "vocab_size = len(ix_to_word) # 12604"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Extracting a small dataset for training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_small_size = 8000\n",
    "train_im_small_idx = []\n",
    "\n",
    "ix = 0\n",
    "qa_data_train_small = []\n",
    "while len(train_im_small_idx) < train_small_size:\n",
    "    if img_pos_train[ix] in train_im_small_idx:\n",
    "        im_ix = train_im_small_idx.index(img_pos_train[ix])\n",
    "    else:\n",
    "        im_ix = len(train_im_small_idx)\n",
    "        train_im_small_idx.append(img_pos_train[ix])\n",
    "    qa_data_train_small.append((ques_train[ix], ques_len_train[ix], im_ix, answers[ix]))\n",
    "    ix += 1\n",
    "\n",
    "train_im_small = []\n",
    "for im_ix in train_im_small_idx:\n",
    "    train_im_small.append(fv_im_train[im_ix, :])\n",
    "\n",
    "with open('data/qa_data_train_small.pkl', 'wb') as fp:\n",
    "    pickle.dump(qa_data_train_small, fp)\n",
    "\n",
    "with h5py.File('data/vqa_data_img_vgg_train_small.h5', 'w') as hf:\n",
    "    hf.create_dataset('images_train', data=train_im_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_small_size = 4000\n",
    "test_im_small_idx = []\n",
    "\n",
    "qa_data_test_small = []\n",
    "while len(test_im_small_idx) < test_small_size:\n",
    "    if img_pos_test[ix] in test_im_small_idx:\n",
    "        im_ix = test_im_small_idx.index(img_pos_test[ix])\n",
    "    else:\n",
    "        im_ix = len(test_im_small_idx)\n",
    "        test_im_small_idx.append(img_pos_test[ix])\n",
    "    qa_data_test_small.append((ques_test[ix], ques_len_test[ix], im_ix, ans_test[ix]))\n",
    "    ix += 1\n",
    "\n",
    "test_im_small = []\n",
    "for im_ix in test_im_small_idx:\n",
    "    test_im_small.append(fv_im_test[im_ix, :])\n",
    "\n",
    "with open('data/qa_data_test_small.pkl', 'wb') as fp:\n",
    "    pickle.dump(qa_data_test_small, fp)\n",
    "\n",
    "with h5py.File('data/vqa_data_img_vgg_test_small.h5', 'w') as hf:\n",
    "    hf.create_dataset('images_test', data=test_im_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Extracting a tiny dataset for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tiny_size = 100\n",
    "train_im_tiny_idx = []\n",
    "\n",
    "ix =0\n",
    "qa_data_train_tiny = []\n",
    "while len(train_im_tiny_idx) < train_tiny_size:\n",
    "    if img_pos_train[ix] in test_im_tiny_idx:\n",
    "        im_ix = train_im_tiny_idx.index(img_pos_train[ix])\n",
    "    else:\n",
    "        im_ix = len(train_im_tiny_idx)\n",
    "        train_im_tiny_idx.append(img_pos_train[ix])\n",
    "    qa_data_train_tiny.append((ques_train[ix], ques_len_train[ix], im_ix, answers[ix]))\n",
    "    ix += 1\n",
    "\n",
    "train_im_tiny = []\n",
    "for im_ix in train_im_tiny_idx:\n",
    "    train_im_tiny.append(fv_im_train[im_ix, :])\n",
    "    \n",
    "with open('data/qa_data_train_tiny.pkl', 'wb') as fp:\n",
    "    pickle.dump(qa_data_train_tiny, fp)\n",
    "\n",
    "with h5py.File('data/vqa_data_img_vgg_train_tiny.h5', 'w') as hf:\n",
    "    hf.create_dataset('images_train', data=train_im_tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tiny_size = 100\n",
    "test_im_tiny_idx = []\n",
    "\n",
    "ix =0\n",
    "qa_data_test_tiny = []\n",
    "while len(test_im_tiny_idx) < test_tiny_size:\n",
    "    if img_pos_test[ix] in test_im_tiny_idx:\n",
    "        im_ix = test_im_tiny_idx.index(img_pos_test[ix])\n",
    "    else:\n",
    "        im_ix = len(test_im_tiny_idx)\n",
    "        test_im_tiny_idx.append(img_pos_test[ix])\n",
    "    qa_data_test_tiny.append((ques_test[ix], ques_len_test[ix], im_ix, ans_test[ix]))\n",
    "    ix += 1\n",
    "\n",
    "test_im_tiny = []\n",
    "for im_ix in test_im_tiny_idx:\n",
    "    test_im_tiny.append(fv_im_test[im_ix, :])\n",
    "    \n",
    "with open('data/qa_data_test_tiny.pkl', 'wb') as fp:\n",
    "    pickle.dump(qa_data_test_tiny, fp)\n",
    "\n",
    "with h5py.File('data/vqa_data_img_vgg_test_tiny.h5', 'w') as hf:\n",
    "    hf.create_dataset('images_test', data=test_im_tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ques, ques_len, im_ix, ans = zip(*qa_data_test_tiny)\n",
    "# print [ix_to_word.get(str(ix), 'UNK') for ix in ques], im_ix, ix_to_ans.get(str(ans), 'UNK')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
